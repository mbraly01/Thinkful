import matplotlib.pyplot as plt
import math
import seaborn as sns
import numpy as np
import pandas as pd
import scipy.stats as stats
from scipy.stats.mstats import winsorize
import sqlalchemy.engine as se
import warnings

warnings.filterwarnings('ignore')
sns.set(style="whitegrid")

postgres_user = 'dsbc_student'
postgres_pw = '7*.8G9QH21'
postgres_host = '142.93.121.174'
postgres_port = '5432'
postgres_db = 'useducation'

engine = se.create_engine('postgresql://{}:{}@{}:{}/{}'.format(postgres_user, postgres_pw
                                                               , postgres_host,
                                                               postgres_port, postgres_db))
used_df = pd.read_sql_query('select * from useducation', con=engine)

engine.dispose()
zero = 0

'''
for i in used_df.columns:
    
    print(used_df[i].describe())
    plt.hist(used_df[i])
    plt.title([i][0])
    plt.show()

#enrollment graph looks very one tailed with a steep drop off around 2000000
#Same goes for total revenue. Are the two of them linked?
#AVG MATH _4_ Score seems favorable to the students (they scored high in a one tailed way
#AVG_MATH_*_Score is looking like a normal distribution
'''
'''
fig = used_df[used_df["STATE"]=="CALIFORNIA"][
    ['YEAR', 'TOTAL_REVENUE']].groupby('YEAR').mean().plot()
used_df[used_df["STATE"]=="CALIFORNIA"][
    ['YEAR', 'TOTAL_EXPENDITURE']].groupby('YEAR').mean().plot(ax=fig)

plt.legend(['revenue','expenditure'])
plt.title('Comparing revenue increases to expenditure increases')
plt.show()
'''

'''
#2. Severe wildfires could lead to more money coming in for students,  and more expenses
to deal with those students.

'''
print(used_df.loc[used_df["STATE"] == "CALIFORNIA", "AVG_MATH_4_SCORE"].describe())
print(used_df.loc[used_df["STATE"] == "CALIFORNIA", "AVG_MATH_8_SCORE"].describe())
print(used_df.loc[used_df["STATE"] == "CALIFORNIA", "AVG_READING_4_SCORE"].describe())
print(used_df.loc[used_df["STATE"] == "CALIFORNIA", "AVG_READING_8_SCORE"].describe())

'''
# 3. Math is better than reading
'''
'''
plt.subplot(2,2,1)
plt.hist(used_df[used_df["STATE"]=="CALIFORNIA"]["AVG_MATH_4_SCORE"])
plt.title("avg_math_4")
plt.subplot(2,2,2)
plt.hist(used_df[used_df["STATE"]=="CALIFORNIA"]["AVG_MATH_8_SCORE"])
plt.title("avg_math_8")
plt.subplot(2,2,3)
plt.hist(used_df[used_df["STATE"]=="CALIFORNIA"]["AVG_READING_4_SCORE"])
plt.title("avg_read_4")
plt.subplot(2,2,4)
plt.hist(used_df[used_df["STATE"]=="CALIFORNIA"]["AVG_READING_8_SCORE"])
plt.title("avg_read_8")
plt.show()
'''
'''
#4. THese distributions are bimodal
'''


used_df1 = used_df
used_df2 = used_df
used_df3 = used_df
print(used_df1["AVG_MATH_4_SCORE"].describe())

#using the mean
for i in range(0, len(used_df1["AVG_MATH_4_SCORE"])):
    if math.isnan(used_df1["AVG_MATH_4_SCORE"][i]) == True or used_df1["AVG_MATH_4_SCORE"][i] == 0:
        used_df1["AVG_MATH_4_SCORE"][i] = used_df1["AVG_MATH_4_SCORE"].mean()

#using the median
for i in range(0, len(used_df2["AVG_MATH_4_SCORE"])):
    if math.isnan(used_df2["AVG_MATH_4_SCORE"][i]) == True or used_df2["AVG_MATH_4_SCORE"][i] == 0:
        used_df2["AVG_MATH_4_SCORE"][i] = used_df2["AVG_MATH_4_SCORE"].median()

#using interpolation
for i in range(1, len(used_df3["AVG_MATH_4_SCORE"])):
    if math.isnan(used_df3["AVG_MATH_4_SCORE"][i]) == True or used_df3["AVG_MATH_4_SCORE"][i] == 0:
        used_df3["AVG_MATH_4_SCORE"][i] = used_df3["AVG_MATH_4_SCORE"][i-1]

print(used_df1["AVG_MATH_4_SCORE"].describe())
print(used_df2["AVG_MATH_4_SCORE"].describe())
print(used_df3["AVG_MATH_4_SCORE"].describe())


'''
#4. with all methods, the standard deviation was cut in half and the center score, 234.76
became both the 25th and 75th quartile

#5 The technique for filling in the missing values substantially affects the distributions
of the variables. Especially in our case, filling with mean or median has the strongest
effect. This is probably due to the fact that we have a lot of missing values in our
data.

The change in the distribution might have some serious effects on our model results.
Hence, instead of filling in the missing values with mean or median, we may fill them
in using interpolation or we may just discard the missing values.
'''
'''

        

