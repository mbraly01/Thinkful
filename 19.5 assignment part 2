import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn import linear_model
import statsmodels.formula.api as smf
from sqlalchemy import create_engine
import statsmodels.api as sm

import warnings
warnings.filterwarnings('ignore')

postgres_user = 'dsbc_student'
postgres_pw = '7*.8G9QH21'
postgres_host = '142.93.121.174'
postgres_port = '5432'
postgres_db = 'houseprices'

engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(
    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))
house_prices_df = pd.read_sql_query('select * from houseprices',con=engine)

# no need for an open connection, as we're only doing a single query
engine.dispose()


house_prices_df.info()

house_prices_df.describe()

'''
We have some columns that are numerical and some are non-numerical. This
distinction is important because if we like to work with non-numerical
variables, we need to convert them to numerical. However, being numerical
doesn't mean being continuous or categorical.
'''
non_numeric_columns = house_prices_df.select_dtypes(['object']).columns
print(non_numeric_columns)
print("The number of non-numerical columns is {}".format(len
                                                         (non_numeric_columns)))

numeric_columns = house_prices_df.select_dtypes(['int64', 'float64']).columns
print(numeric_columns)
print("The number of numerical columns is {}".format(len(numeric_columns)))

#missing data
total_missing = house_prices_df.isnull().sum().sort_values(ascending=False)
percent_missing = (house_prices_df.isnull().sum()/house_prices_df.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total_missing, percent_missing], axis=1, keys=['Total', 'Percent'])
missing_data.head(20)


#Only 19 of the features have missing values. Since, in this checkpoint we'll
#not be using any of these 19 features; we do nothing here. But if you want to
#use them in your model, you need to decide what to do with the missing values
# the sales price seems to be non normal
'''
plt.hist(house_prices_df.saleprice)
plt.title("The distribution of sale prices")
plt.xlabel("sale prices")
plt.ylabel("number of occurrence")
plt.show()
'''
np.abs(house_prices_df[numeric_columns].iloc[:,1:].corr().
       loc[:,"saleprice"]).sort_values(ascending=False)



print(house_prices_df.info())
house_prices_df = pd.concat([house_prices_df,pd.get_dummies(house_prices_df.mszoning, prefix="mszoning", drop_first=True)], axis=1)
house_prices_df = pd.concat([house_prices_df,pd.get_dummies(house_prices_df.street, prefix="street", drop_first=True)], axis=1)
dummy_column_names = list(pd.get_dummies(house_prices_df.mszoning, prefix="mszoning", drop_first=True).columns)
dummy_column_names = dummy_column_names + list(pd.get_dummies(house_prices_df.street, prefix="street", drop_first=True).columns)


X = house_prices_df[['overallqual', 'grlivarea', 'openporchsf', 'garagearea',
                     'totalbsmtsf','garagecars'] + dummy_column_names]

Y = house_prices_df.saleprice
'''

'''
X = sm.add_constant(X)

results = sm.OLS(Y, X).fit()

print(results.summary())

'''
#Question 1: THe R^2 and R^2 adjusted are both high which is good. The AIC and BICs are
at 3.5e+4. we will try to bring them down

#Question 2;
with overallcond instead of grlivarea: Rsquared is 7.17 (lower) and AIC/BIC is higher
(3.52e+4)

with openporchsf instead of garage cars: Rsquared is .76 and AIC BIC is 3.5e+4

Adding garagecars back: a small impact on the model

Question 3: THe openporchsf model seems to be the best. It has the same number of
variables with score improvements



'''
